{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeEyIox5WN1x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf49bf70-0a14-4a0b-b74a-e4bb2fcc0a1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "drive.mount(\"/content/gdrive\")\n",
        "os.chdir(\"/content/gdrive/MyDrive/ReviewVideoSummarization\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=\"AppleWatch8\"\n",
        "text_path=\"text/\"+dataset\n",
        "\n",
        "text_data = [f for f in listdir(text_path) if isfile(join(text_path, f))]"
      ],
      "metadata": {
        "id": "1pi3tbf2Wmy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers\n",
        "from transformers import pipeline\n",
        "def extract_sentiment(text):\n",
        "  sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
        "  sentiment=sentiment_pipeline(data)\n",
        "  return sentiment\n",
        "\n",
        "counter=1\n",
        "for t in text_data:\n",
        "  if(counter>0): #Test\n",
        "    segment=1\n",
        "    fh = open(\"sentiment/\"+t, \"w+\")\n",
        "    with open(text_path+\"/\"+t) as f:\n",
        "      lines=f.readlines()\n",
        "    text=str(lines[0])\n",
        "    text=text.split(\"@\")\n",
        "    all_text=\"\"\n",
        "    sentiment=[]\n",
        "    for i in range(len(text)):\n",
        "      data = text[i]\n",
        "      res=extract_sentiment(data)\n",
        "      fh.write(t.split('.')[0]+\",\"+str(segment)+\",\"+res[0]['label']+\",\"+str(res[0]['score'])+\"\\n\")\n",
        "      segment=segment+1\n",
        "      sentiment.append(res)\n",
        "      all_text=all_text+\" \"+str(data)\n",
        "    print(sentiment)\n",
        "  counter=counter+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ilHEm-HW_1H",
        "outputId": "a97f276d-f6ec-45f1-b314-16f8e7e45dc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'label': 'NEGATIVE', 'score': 0.9939976930618286}], [{'label': 'NEGATIVE', 'score': 0.8075757026672363}], [{'label': 'NEGATIVE', 'score': 0.9486103653907776}], [{'label': 'NEGATIVE', 'score': 0.9967548251152039}], [{'label': 'POSITIVE', 'score': 0.9642132520675659}], [{'label': 'NEGATIVE', 'score': 0.9983077049255371}], [{'label': 'POSITIVE', 'score': 0.8749812245368958}], [{'label': 'NEGATIVE', 'score': 0.6370437145233154}], [{'label': 'NEGATIVE', 'score': 0.9172757863998413}], [{'label': 'POSITIVE', 'score': 0.995752215385437}], [{'label': 'NEGATIVE', 'score': 0.9826055765151978}], [{'label': 'NEGATIVE', 'score': 0.984808087348938}], [{'label': 'NEGATIVE', 'score': 0.9988081455230713}], [{'label': 'POSITIVE', 'score': 0.9711464643478394}], [{'label': 'POSITIVE', 'score': 0.9912091493606567}], [{'label': 'POSITIVE', 'score': 0.9938440322875977}], [{'label': 'POSITIVE', 'score': 0.8824312090873718}], [{'label': 'NEGATIVE', 'score': 0.9990116357803345}], [{'label': 'NEGATIVE', 'score': 0.9900147914886475}], [{'label': 'NEGATIVE', 'score': 0.9834504127502441}], [{'label': 'POSITIVE', 'score': 0.9972537159919739}], [{'label': 'POSITIVE', 'score': 0.9888745546340942}], [{'label': 'POSITIVE', 'score': 0.9711446762084961}], [{'label': 'POSITIVE', 'score': 0.9929053783416748}], [{'label': 'POSITIVE', 'score': 0.9602676033973694}]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_text=\"\"\n",
        "for t in text_data:\n",
        "  with open(text_path+\"/\"+t) as f:\n",
        "    lines=f.readlines()\n",
        "  text=str(lines[0])\n",
        "  text=text.split(\"@\")\n",
        "\n",
        "  for i in range(len(text)):\n",
        "    data = text[i]\n",
        "    all_text=all_text+\" \"+str(data)\n",
        ""
      ],
      "metadata": {
        "id": "8g5qTO1kXBup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keybert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNktfPzzq_WH",
        "outputId": "af1d8dee-3012-4298-f67d-fd40c0475da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keybert in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from keybert) (1.21.6)\n",
            "Requirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.7/dist-packages (from keybert) (2.2.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from keybert) (1.0.2)\n",
            "Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.7/dist-packages (from keybert) (12.4.4)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.4.0->keybert) (4.2.0)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.4.0->keybert) (0.9.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.4.0->keybert) (2.6.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (3.1.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.1.96)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.12.0+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.64.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.19.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (3.2.5)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.7.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (1.11.0+cu113)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers>=0.3.8->keybert) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2.10)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keybert import KeyBERT\n",
        "kw_model = KeyBERT()\n",
        "keywords = kw_model.extract_keywords(all_text,top_n=20)\n",
        "print(keywords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKm4fSjRrDB9",
        "outputId": "c1c73cb1-3b07-4b15-ddcc-6b768ae7f01e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('bose', 0.4277), ('earphones', 0.3998), ('headphones', 0.3894), ('headphone', 0.3682), ('headband', 0.362), ('crystal', 0.3343), ('mkbhd', 0.3316), ('tracks', 0.324), ('improved', 0.3179), ('quality', 0.3139), ('design', 0.3132), ('airpods', 0.3053), ('sleek', 0.3023), ('improvement', 0.3018), ('bass', 0.2976), ('headset', 0.2976), ('ear', 0.2974), ('hearing', 0.293), ('audio', 0.2888), ('costly', 0.288)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keywords2=kw_model.extract_keywords(all_text, keyphrase_ngram_range=(1, 2), stop_words='english', top_n=20)\n",
        "print(keywords2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srTe2TvmrIRs",
        "outputId": "0a056e1c-56b4-47ab-d78c-97ec46adb1bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('quality bose', 0.5473), ('better bose', 0.5072), ('new bose', 0.4969), ('bose headphones', 0.4807), ('headphone designed', 0.446), ('quality tracks', 0.4434), ('headphones compare', 0.4384), ('saksham headphones', 0.4334), ('headphones finally', 0.4323), ('bose', 0.4277), ('headphones heavens', 0.4269), ('headphone product', 0.4257), ('best headphones', 0.4249), ('bose audio', 0.4216), ('flagship headphone', 0.4209), ('ear headphones', 0.4196), ('headphones really', 0.4178), ('soon bose', 0.4159), ('designed headband', 0.4134), ('headphones best', 0.4112)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "counter=1\n",
        "file_path=\"keyword/\"+dataset+\"/keyword.txt\"\n",
        "print(file_path)\n",
        "fh = open(file_path, \"w+\")\n",
        "for t in text_data:\n",
        "  segment=1\n",
        "  with open(text_path+\"/\"+t) as f:\n",
        "    lines=f.readlines()\n",
        "    text=str(lines[0])\n",
        "    text=text.split(\"@\")\n",
        "    for i in range(len(text)):\n",
        "      data = text[i]\n",
        "      g1_score=0\n",
        "      g2_score=0\n",
        "      for kw in keywords:\n",
        "        count=data.count(kw[0])\n",
        "        g1_score=g1_score+count*kw[1]\n",
        "        #print(g1_score)\n",
        "      for kw in keywords2:\n",
        "        count=data.count(kw[0])\n",
        "        g2_score=g2_score+count*kw[1]\n",
        "        #print(g2_score)\n",
        "      fh.write(t.split('.')[0]+\",\"+str(segment)+\",\"+str(g1_score)+\",\"+str(g2_score)+\"\\n\")\n",
        "      segment=segment+1\n",
        "  counter=counter+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTJKT3XrrO1A",
        "outputId": "502a2ac3-e64b-4080-8fac-1bac0bd7b8cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keyword/bosh700/keyword.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3VYql48j5ncC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}